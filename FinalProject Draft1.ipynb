{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1708c749-0f30-40e5-9e6b-35f34db0adfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip -q install yfinance==0.2.52 pandas-datareader==0.10.0 python-dotenv==1.0.1 \\\n",
    "               requests==2.32.3 beautifulsoup4==4.12.3 lxml==5.3.0 rapidfuzz==3.9.7 \\\n",
    "               nltk==3.9.1 pydantic==2.9.2 PyYAML==6.0.2\n",
    "import nltk; nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232611ec-4a6f-409b-91f7-bf1b90f52580",
   "metadata": {},
   "source": [
    "## Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7cefe39-ecb1-443e-b33b-3728712190ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, re\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "ROOT = pathlib.Path.cwd() / \"agent_finance_nb\"\n",
    "ROOT.mkdir(parents=True, exist_ok=True)\n",
    "os.chdir(ROOT)  # ensure .env is here or parent\n",
    "load_dotenv(find_dotenv(usecwd=True) or \".env\")\n",
    "# strip accidental whitespace from pasted keys\n",
    "for k in [\"OPENAI_API_KEY\",\"NEWSAPI_KEY\",\"ALPHAVANTAGE_API_KEY\",\"FRED_API_KEY\"]:\n",
    "    v = os.getenv(k); \n",
    "    if v: os.environ[k] = re.sub(r\"\\s+\", \"\", v)\n",
    "# force official API base\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://api.openai.com/v1\"\n",
    "\n",
    "# minimal config / memory file\n",
    "(mem_path := pathlib.Path(\"data/memory.json\")).parent.mkdir(parents=True, exist_ok=True)\n",
    "if not mem_path.exists(): mem_path.write_text(\"[]\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8037ffde-7331-4b1e-9067-59617286a42c",
   "metadata": {},
   "source": [
    "##  Rate control core (token bucket + queue + circuit breaker) + disk cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20748cbf-c1a1-4053-b608-b9faf871cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rate_control.py\n",
    "import time, json, pathlib, hashlib, threading, random\n",
    "from typing import Any\n",
    "\n",
    "CACHE_DIR = pathlib.Path(\"data/.cache\"); CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _cache_path(ns: str, key: str) -> pathlib.Path:\n",
    "    h = hashlib.sha256(key.encode()).hexdigest()[:40]\n",
    "    p = CACHE_DIR / ns; p.mkdir(exist_ok=True)\n",
    "    return p / f\"{h}.json\"\n",
    "\n",
    "def cache_get(ns: str, key: str, ttl_sec: int):\n",
    "    p = _cache_path(ns, key)\n",
    "    if not p.exists(): return None\n",
    "    if time.time() - p.stat().st_mtime > ttl_sec: return None\n",
    "    try: return json.loads(p.read_text())\n",
    "    except: return None\n",
    "\n",
    "def cache_set(ns: str, key: str, obj: Any):\n",
    "    _cache_path(ns, key).write_text(json.dumps(obj))\n",
    "\n",
    "class CircuitBreaker:\n",
    "    def __init__(self, fail_threshold:int=3, open_seconds:int=30):\n",
    "        self.fail_threshold = fail_threshold\n",
    "        self.open_seconds = open_seconds\n",
    "        self.fail_count = 0\n",
    "        self.open_until = 0.0\n",
    "        self.lock = threading.Lock()\n",
    "    def record_success(self):\n",
    "        with self.lock: self.fail_count = 0; self.open_until = 0.0\n",
    "    def record_failure(self):\n",
    "        with self.lock:\n",
    "            self.fail_count += 1\n",
    "            if self.fail_count >= self.fail_threshold:\n",
    "                self.open_until = time.time() + self.open_seconds\n",
    "    def is_open(self): \n",
    "        with self.lock: return time.time() < self.open_until\n",
    "\n",
    "class TokenBucket:\n",
    "    def __init__(self, capacity:int, refill_per_sec:float):\n",
    "        self.capacity = capacity; self.tokens = capacity\n",
    "        self.refill_per_sec = refill_per_sec\n",
    "        self.last = time.time(); self.lock = threading.Lock()\n",
    "    def _refill(self):\n",
    "        now = time.time(); dt = now - self.last; self.last = now\n",
    "        self.tokens = min(self.capacity, self.tokens + dt*self.refill_per_sec)\n",
    "    def take(self, tokens:float=1.0):\n",
    "        with self.lock:\n",
    "            self._refill()\n",
    "            if self.tokens >= tokens:\n",
    "                self.tokens -= tokens; return 0.0\n",
    "            deficit = tokens - self.tokens\n",
    "            wait = deficit / self.refill_per_sec\n",
    "            self.tokens = 0.0\n",
    "        return wait\n",
    "\n",
    "class RequestQueue:\n",
    "    def __init__(self, max_concurrent:int=1, min_gap_sec:float=0.3):\n",
    "        self.sema = threading.Semaphore(max_concurrent)\n",
    "        self.min_gap = min_gap_sec\n",
    "        self.last_ts = 0.0\n",
    "        self.lock = threading.Lock()\n",
    "    def acquire(self):\n",
    "        self.sema.acquire()\n",
    "        with self.lock:\n",
    "            gap = time.time() - self.last_ts\n",
    "            if gap < self.min_gap: time.sleep(self.min_gap - gap)\n",
    "    def release(self):\n",
    "        with self.lock: self.last_ts = time.time()\n",
    "        self.sema.release()\n",
    "\n",
    "def honor_retry_after(resp, default_sleep):\n",
    "    try:\n",
    "        ra = resp.headers.get(\"Retry-After\")\n",
    "        if not ra: return default_sleep\n",
    "        val = float(ra) if ra.isdigit() else default_sleep\n",
    "        return max(val, default_sleep)\n",
    "    except: return default_sleep\n",
    "\n",
    "def guarded_call(name:str, bucket:TokenBucket, queue:RequestQueue, breaker:CircuitBreaker, fn, *, max_retries:int=5, base:float=0.7, max_sleep:float=12.0):\n",
    "    if breaker.is_open(): raise RuntimeError(f\"{name} circuit open; cooling down.\")\n",
    "    w = bucket.take(1.0)\n",
    "    if w>0: time.sleep(w)\n",
    "    queue.acquire()\n",
    "    try:\n",
    "        last_exc = None\n",
    "        for i in range(max_retries):\n",
    "            try:\n",
    "                resp = fn(); breaker.record_success(); return resp\n",
    "            except Exception as e:\n",
    "                status = getattr(getattr(e, \"response\", None), \"status_code\", None)\n",
    "                breaker.record_failure()\n",
    "                if i == max_retries-1: raise\n",
    "                sleep = min(max_sleep, base*(2**i))*(0.7 + 0.6*random.random())\n",
    "                resp = getattr(e, \"response\", None)\n",
    "                if resp is not None: sleep = honor_retry_after(resp, sleep)\n",
    "                print(f\"[{name}] retry {i+1}/{max_retries} status={status} sleep={sleep:.2f}s\")\n",
    "                time.sleep(sleep); last_exc = e\n",
    "        raise last_exc\n",
    "    finally:\n",
    "        queue.release()\n",
    "\n",
    "# Provider profiles (conservative defaults)\n",
    "OPENAI_BUCKET = TokenBucket(capacity=50, refill_per_sec=50/60)\n",
    "OPENAI_Q = RequestQueue(max_concurrent=1, min_gap_sec=0.25)\n",
    "OPENAI_CB = CircuitBreaker(fail_threshold=2, open_seconds=15)\n",
    "\n",
    "ALPHA_BUCKET = TokenBucket(capacity=4, refill_per_sec=4/60)     # Alpha Vantage ~5rpm free → set 4rpm\n",
    "ALPHA_Q = RequestQueue(max_concurrent=1, min_gap_sec=0.6)\n",
    "ALPHA_CB = CircuitBreaker(fail_threshold=2, open_seconds=30)\n",
    "\n",
    "NEWS_BUCKET = TokenBucket(capacity=10, refill_per_sec=10/60)    # modest throttle\n",
    "NEWS_Q = RequestQueue(max_concurrent=1, min_gap_sec=0.4)\n",
    "NEWS_CB = CircuitBreaker(fail_threshold=2, open_seconds=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c686de-bef4-48f6-8c73-16cef45412ca",
   "metadata": {},
   "source": [
    "## LLM client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c781c6e9-83e6-48f3-9c8b-8c8d449cf8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_client.py\n",
    "import os, requests, json, hashlib\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "@dataclass\n",
    "class ChatMessage:\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "def _llm_ckey(payload: dict) -> str:\n",
    "    return hashlib.sha256(json.dumps(payload, sort_keys=True).encode()).hexdigest()\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self, model: str=\"gpt-4o-mini\", temperature: float=0.2, base_url: Optional[str]=None):\n",
    "        base = base_url or os.getenv(\"OPENAI_BASE_URL\") or \"https://api.openai.com/v1\"\n",
    "        if not base.startswith(\"https://api.openai.com\"): base = \"https://api.openai.com/v1\"\n",
    "        self.base = base.rstrip(\"/\")\n",
    "        self.model = model; self.temperature = temperature\n",
    "        self.key = (os.getenv(\"OPENAI_API_KEY\") or \"\").strip()\n",
    "        if not self.key: raise RuntimeError(\"OPENAI_API_KEY missing\")\n",
    "\n",
    "    def chat(self, messages: List[Dict] | List[ChatMessage], max_tokens: int = 700) -> str:\n",
    "        headers = {\"Authorization\": f\"Bearer {self.key}\", \"Content-Type\": \"application/json\"}\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"messages\": [{\"role\": (m[\"role\"] if isinstance(m, dict) else m.role),\n",
    "                          \"content\": (m[\"content\"] if isinstance(m, dict) else m.content)} for m in messages],\n",
    "        }\n",
    "        ckey = _llm_ckey({\"url\": self.base + \"/chat/completions\", **payload})\n",
    "        hit = cache_get(\"llm\", ckey, ttl_sec=3600)\n",
    "        if hit: return hit[\"text\"]\n",
    "\n",
    "        def _post():\n",
    "            r = requests.post(self.base + \"/chat/completions\", json=payload, headers=headers, timeout=60, allow_redirects=False)\n",
    "            if r.is_redirect and r.status_code in (307,308) and r.headers.get(\"Location\"):\n",
    "                r = requests.post(r.headers[\"Location\"], json=payload, headers=headers, timeout=60, allow_redirects=False)\n",
    "            r.raise_for_status(); return r\n",
    "\n",
    "        r = guarded_call(\"openai\", OPENAI_BUCKET, OPENAI_Q, OPENAI_CB, _post, max_retries=6, base=0.8, max_sleep=20.0)\n",
    "        text = r.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        cache_set(\"llm\", ckey, {\"text\": text})\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7e66d-36da-4e21-a3a4-ba41ec9f444d",
   "metadata": {},
   "source": [
    "## Data tools (Prices → Stooq→Yahoo→Alpha; NewsAPI; FRED macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "416aa192-887d-4725-8b74-cd493103153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_tool.py\n",
    "import datetime as dt, requests, yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "from typing import Dict, Any\n",
    "import os\n",
    "\n",
    "ALPHA_KEY = os.getenv(\"ALPHAVANTAGE_API_KEY\")\n",
    "\n",
    "def _hist_to_rows(df, days:int):\n",
    "    if df is None or df.empty: return []\n",
    "    df = df.sort_index()\n",
    "    df = df.tail(days)\n",
    "    rows=[]\n",
    "    for idx, row in df.iterrows():\n",
    "        rows.append({\n",
    "            \"date\": (idx.date().isoformat() if hasattr(idx, \"date\") else str(idx)),\n",
    "            \"open\": float(row.get(\"Open\", row.get(\"open\", 0.0))),\n",
    "            \"high\": float(row.get(\"High\", row.get(\"high\", 0.0))),\n",
    "            \"low\":  float(row.get(\"Low\",  row.get(\"low\", 0.0))),\n",
    "            \"close\":float(row.get(\"Close\",row.get(\"close\",0.0))),\n",
    "            \"volume\": int(row.get(\"Volume\", row.get(\"volume\", 0))),\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "class PriceTool:\n",
    "    def fetch(self, symbol: str, days: int = 20) -> Dict[str, Any]:\n",
    "        key = f\"{symbol}:{days}\"\n",
    "        hit = cache_get(\"prices\", key, ttl_sec=3600)\n",
    "        if hit: return hit\n",
    "\n",
    "        # 1) Stooq (daily)\n",
    "        def _stooq():\n",
    "            df = pdr.DataReader(symbol, \"stooq\")\n",
    "            return _hist_to_rows(df, days)\n",
    "        try:\n",
    "            rows = guarded_call(\"stooq\", NEWS_BUCKET, NEWS_Q, NEWS_CB, _stooq, max_retries=3, base=0.6, max_sleep=6.0)\n",
    "            if rows:\n",
    "                out = {\"symbol\": symbol, \"history\": rows}; cache_set(\"prices\", key, out); return out\n",
    "        except Exception as e: print(\"[prices] stooq failed:\", e)\n",
    "\n",
    "        # 2) Yahoo\n",
    "        def _yahoo():\n",
    "            end = dt.date.today(); start = end - dt.timedelta(days=days*2)\n",
    "            df = yf.download(symbol, start=start.isoformat(), end=end.isoformat(), progress=False)\n",
    "            if df is None or df.empty:\n",
    "                resp = requests.Response(); resp.status_code = 429\n",
    "                raise requests.HTTPError(response=resp)\n",
    "            return _hist_to_rows(df, days)\n",
    "        try:\n",
    "            rows = guarded_call(\"yahoo\", NEWS_BUCKET, NEWS_Q, NEWS_CB, _yahoo, max_retries=4, base=0.8, max_sleep=10.0)\n",
    "            if rows:\n",
    "                out = {\"symbol\": symbol, \"history\": rows}; cache_set(\"prices\", key, out); return out\n",
    "        except Exception as e: print(\"[prices] yahoo failed:\", e)\n",
    "\n",
    "        # 3) Alpha Vantage (strict)\n",
    "        def _alpha():\n",
    "            r = requests.get(\n",
    "                \"https://www.alphavantage.co/query\",\n",
    "                params={\"function\":\"TIME_SERIES_DAILY_ADJUSTED\",\"symbol\":symbol,\"outputsize\":\"compact\",\"apikey\":ALPHA_KEY},\n",
    "                timeout=20)\n",
    "            r.raise_for_status()\n",
    "            ts = r.json().get(\"Time Series (Daily)\", {}) or {}\n",
    "            rows_sorted = sorted(ts.items())[-days:]\n",
    "            out=[]\n",
    "            for d,v in rows_sorted:\n",
    "                out.append({\n",
    "                    \"date\": d, \"open\": float(v[\"1. open\"]), \"high\": float(v[\"2. high\"]),\n",
    "                    \"low\": float(v[\"3. low\"]), \"close\": float(v[\"4. close\"]),\n",
    "                    \"volume\": int(float(v.get(\"6. volume\",\"0\")))\n",
    "                })\n",
    "            return out\n",
    "        try:\n",
    "            rows = guarded_call(\"alpha\", ALPHA_BUCKET, ALPHA_Q, ALPHA_CB, _alpha, max_retries=4, base=0.8, max_sleep=20.0)\n",
    "            out = {\"symbol\": symbol, \"history\": rows}; cache_set(\"prices\", key, out); return out\n",
    "        except Exception as e:\n",
    "            print(\"[prices] alpha failed:\", e)\n",
    "            return {\"symbol\": symbol, \"history\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "059f3867-dd39-444d-bd72-72cc279d9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_tool.py\n",
    "import os, requests\n",
    "from typing import List, Dict\n",
    "class NewsTool:\n",
    "    def __init__(self): self.key = os.getenv(\"NEWSAPI_KEY\")\n",
    "    def fetch(self, symbol: str, limit: int = 12) -> List[Dict]:\n",
    "        key = f\"{symbol}:{limit}\"\n",
    "        hit = cache_get(\"news\", key, ttl_sec=600)\n",
    "        if hit: return hit\n",
    "        def _call():\n",
    "            r = requests.get(\"https://newsapi.org/v2/everything\",\n",
    "                             params={\"q\": symbol, \"pageSize\": limit, \"language\":\"en\",\n",
    "                                     \"sortBy\":\"publishedAt\",\"apiKey\": self.key},\n",
    "                             timeout=30)\n",
    "            r.raise_for_status()\n",
    "            return [{\"title\": a.get(\"title\"), \"url\": a.get(\"url\"),\n",
    "                     \"publishedAt\": a.get(\"publishedAt\"), \"source\": a.get(\"source\",{}).get(\"name\"),\n",
    "                     \"content\": a.get(\"content\") or \"\"} for a in r.json().get(\"articles\", [])]\n",
    "        items = guarded_call(\"newsapi\", NEWS_BUCKET, NEWS_Q, NEWS_CB, _call, max_retries=5, base=0.7, max_sleep=15.0)\n",
    "        cache_set(\"news\", key, items)\n",
    "        return items[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2cded99-d225-4825-a8c7-29505528e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fred_tool.py\n",
    "import os, requests\n",
    "from typing import Dict, Any, List\n",
    "FRED_KEY = os.getenv(\"FRED_API_KEY\")\n",
    "FRED_BUCKET = TokenBucket(capacity=30, refill_per_sec=30/60)\n",
    "FRED_Q = RequestQueue(max_concurrent=1, min_gap_sec=0.2)\n",
    "FRED_CB = CircuitBreaker(fail_threshold=2, open_seconds=10)\n",
    "\n",
    "class FREDTool:\n",
    "    BASE = \"https://api.stlouisfed.org/fred\"\n",
    "    def _series_obs(self, sid: str) -> List[Dict[str, Any]]:\n",
    "        if not FRED_KEY: return []\n",
    "        params = {\"series_id\": sid, \"api_key\": FRED_KEY, \"file_type\": \"json\"}\n",
    "        def _call():\n",
    "            r = requests.get(f\"{self.BASE}/series/observations\", params=params, timeout=20)\n",
    "            r.raise_for_status(); return r.json().get(\"observations\", [])\n",
    "        obs = guarded_call(\"fred\", FRED_BUCKET, FRED_Q, FRED_CB, _call, max_retries=4, base=0.6, max_sleep=8.0)\n",
    "        return [o for o in obs if o.get(\"value\") not in (None, \".\", \"\")]\n",
    "    def latest_snapshot(self) -> Dict[str, Any]:\n",
    "        series = {\"UNRATE\":\"Unemployment Rate (%)\",\"DGS10\":\"10Y Treasury Yield (%)\",\n",
    "                  \"CPIAUCSL\":\"CPI (Index 1982-84=100)\", \"FEDFUNDS\":\"Fed Funds Rate (%)\"}\n",
    "        out={}\n",
    "        for sid,name in series.items():\n",
    "            key=f\"fred:{sid}\"; hit=cache_get(\"fred\", key, ttl_sec=6*3600)\n",
    "            if hit: out[name]=hit; continue\n",
    "            obs=self._series_obs(sid)\n",
    "            if obs:\n",
    "                last=obs[-1]; val={\"date\": last.get(\"date\"), \"value\": last.get(\"value\")}\n",
    "                out[name]=val; cache_set(\"fred\", key, val)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3510884-8124-419a-8a3b-4e4b387a0882",
   "metadata": {},
   "source": [
    "## Prompt chain, routing, analyzers, quant, macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09497d12-ecc0-4777-918c-6bcd4120777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain + analyzers\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re, html, hashlib, math\n",
    "from typing import List, Dict\n",
    "\n",
    "def _norm_title(t): \n",
    "    if not t: return \"\"\n",
    "    t = html.unescape(t); t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    t = re.sub(r\"\\s*[-–—]\\s*(Bloomberg|Reuters|WSJ|CNBC|Yahoo Finance|The Verge|TechCrunch)\\s*$\",\"\",t,flags=re.I)\n",
    "    return t\n",
    "\n",
    "def _dedupe(items: List[Dict]) -> List[Dict]:\n",
    "    seen=set(); out=[]\n",
    "    for d in items:\n",
    "        t=_norm_title(d.get(\"title\")); u=(d.get(\"url\") or \"\").strip()\n",
    "        key=hashlib.sha256((t+\"|\"+u).encode()).hexdigest()[:16]\n",
    "        if key in seen: continue\n",
    "        seen.add(key); out.append({**d,\"title\":t})\n",
    "    return out\n",
    "\n",
    "def pc_ingest(news_items: List[Dict]) -> List[Dict]: return _dedupe(news_items or [])\n",
    "\n",
    "def pc_preprocess(items: List[Dict]) -> List[Dict]:\n",
    "    out=[]\n",
    "    for d in items:\n",
    "        t=_norm_title(d.get(\"title\"))\n",
    "        text=(d.get(\"content\") or t or \"\").strip()\n",
    "        text=re.sub(r\"<[^>]+>\",\" \",text); text=re.sub(r\"\\s+\",\" \",text).strip()\n",
    "        sents=sent_tokenize(text) if text else []\n",
    "        out.append({**d,\"title\":t,\"sentences\":sents,\"raw\":text})\n",
    "    return out\n",
    "\n",
    "# classifier\n",
    "EARN=r\"(earnings|results|q[1-4]\\b|fY\\d{2}|guidance|eps|revenue|margin|outlook)\"\n",
    "ANALYST=r\"(upgrade|downgrade|price target|initiates coverage|maintains|overweight|underweight|buy rating|sell rating|neutral)\"\n",
    "MACRO=r\"(fed|federal reserve|cpi|inflation|ppi|yield|treasury|jobs report|payrolls|unemployment|rate hike|rate cut|dot plot)\"\n",
    "MA=r\"(acquire|acquisition|merger|merge|takeover|buyout|M&A|spinoff|spin-off|divest)\"\n",
    "LEGAL=r\"(lawsuit|sues|sued|settlement|probe|investigation|antitrust|FTC|DoJ|SEC|regulator|regulatory)\"\n",
    "PRODUCT=r\"(launch|unveil|introduc(e|es|ed)|ship|rollout|preorder|prototype|roadmap|AI model|chip|GPU|iPhone|feature)\"\n",
    "CAPITAL=r\"(buyback|repurchase|dividend|payout|special dividend|split|secondary|offering|convertible|notes)\"\n",
    "MGMT=r\"(CEO|CFO|COO|chair|exec|resigns|steps down|appointed|names|leadership|board)\"\n",
    "SUPPLY=r\"(supply chain|shortage|capacity|inventory|backlog|fabs?|foundry|wafer|shipment|logistics|strike)\"\n",
    "RISK=r\"(recall|outage|security|hack|breach|downtime|fire|accident|halt|ban|sanction)\"\n",
    "_PATTERNS=[(\"earnings\",EARN),(\"analyst\",ANALYST),(\"macro\",MACRO),(\"ma\",MA),(\"legal\",LEGAL),(\"product\",PRODUCT),\n",
    "           (\"capital\",CAPITAL),(\"management\",MGMT),(\"supply\",SUPPLY),(\"risk\",RISK)]\n",
    "\n",
    "def pc_classify(items: List[Dict]) -> List[Dict]:\n",
    "    out=[]\n",
    "    for d in items:\n",
    "        t=(d.get(\"title\") or \"\").lower(); scores=[]\n",
    "        for name,pat in _PATTERNS:\n",
    "            if re.search(pat,t,re.I): scores.append(name)\n",
    "        label=scores[0] if scores else \"news\"\n",
    "        out.append({**d,\"label\":label})\n",
    "    return out\n",
    "\n",
    "def pc_extract(items: List[Dict]) -> List[Dict]:\n",
    "    out=[]\n",
    "    for d in items:\n",
    "        s=d.get(\"sentences\",[]); top=sorted(s,key=len,reverse=True)[:2]\n",
    "        out.append({**d,\"keypoints\":top})\n",
    "    return out\n",
    "\n",
    "def pc_summarize(llm, symbol: str, items: List[Dict]) -> str:\n",
    "    if not items:\n",
    "        return f\"No recent news for {symbol}. Monitor earnings, guidance, and macro catalysts.\"\n",
    "    bullets=[]\n",
    "    for d in items[:5]:\n",
    "        bullets.append(f\"- [{d.get('label','news')}] {d.get('title')}\")\n",
    "        for kp in d.get(\"keypoints\",[])[:2]: bullets.append(f\"  • {kp}\")\n",
    "    prompt=(f\"You are a finance analyst. Summarize these items for {symbol} in 120-180 words, \"\n",
    "            f\"calling out catalysts and risks.\\n\\n\"+\"\\n\".join(bullets))\n",
    "    return llm.chat([{\"role\":\"system\",\"content\":\"Be concise, neutral, decision-useful.\"},\n",
    "                     {\"role\":\"user\",\"content\":prompt}], max_tokens=600)\n",
    "\n",
    "# analyzers + quant + macro\n",
    "def _pct_ret(hist: List[Dict], n:int)->float:\n",
    "    if len(hist)<n+1: return float(\"nan\")\n",
    "    p0=hist[-(n+1)][\"close\"]; p1=hist[-1][\"close\"]\n",
    "    return (p1-p0)/p0*100.0 if p0 else float(\"nan\")\n",
    "def _sma(hist: List[Dict], n:int)->float:\n",
    "    if len(hist)<n: return float(\"nan\")\n",
    "    return sum(h[\"close\"] for h in hist[-n:])/n\n",
    "def _vol(hist: List[Dict], n:int=10)->float:\n",
    "    if len(hist)<n+1: return float(\"nan\")\n",
    "    import math\n",
    "    rets=[]\n",
    "    for i in range(-n,0):\n",
    "        p0=hist[i-1][\"close\"]; p1=hist[i][\"close\"]\n",
    "        if p0 and p1: rets.append(math.log(p1/p0))\n",
    "    if not rets: return float(\"nan\")\n",
    "    m=sum(rets)/len(rets); var=sum((r-m)**2 for r in rets)/(len(rets)-1)\n",
    "    return (var**0.5)* (252**0.5) *100.0\n",
    "\n",
    "def build_metrics(prices: Dict)->Dict[str,float]:\n",
    "    h=prices.get(\"history\",[])\n",
    "    if not h: return {}\n",
    "    return {\"R5%\":_pct_ret(h,5),\"R10%\":_pct_ret(h,10),\"R20%\":_pct_ret(h,20),\n",
    "            \"SMA5\":_sma(h,5),\"SMA10\":_sma(h,10),\"SMA20\":_sma(h,20),\"Vol10%\":_vol(h,10)}\n",
    "\n",
    "def _fmt(x): \n",
    "    return \"n/a\" if (x is None or isinstance(x,float) and (math.isnan(x) or math.isinf(x))) else f\"{x:.2f}\"\n",
    "\n",
    "def metrics_table(m: Dict[str,float])->str:\n",
    "    if not m: return \"(no price history)\"\n",
    "    order=[\"R5%\",\"R10%\",\"R20%\",\"SMA5\",\"SMA10\",\"SMA20\",\"Vol10%\"]\n",
    "    hdr=\"| Metric | Value |\\n|---|---|\\n\"\n",
    "    rows=\"\\n\".join([f\"| {k} | {_fmt(m.get(k))}{'%' if k.endswith('%') else ''} |\" for k in order])\n",
    "    return hdr+rows\n",
    "\n",
    "def analyze_news(symbol: str, docs: List[Dict]) -> str:\n",
    "    titles=\"; \".join(d.get(\"title\",\"\") for d in docs[:3])\n",
    "    return f\"News summary for {symbol}: {titles}\"\n",
    "\n",
    "def analyze_earnings(symbol: str, docs: List[Dict]) -> str:\n",
    "    titles=\", \".join(d.get(\"title\",\"\") for d in docs[:3])\n",
    "    return f\"Earnings items for {symbol}: {titles}\"\n",
    "\n",
    "def analyze_market(symbol: str, docs: List[Dict], *, prices: Dict|None=None, fred: Dict|None=None) -> str:\n",
    "    m=build_metrics(prices or {})\n",
    "    if not m: return f\"Market snapshot for {symbol}: no price history.\"\n",
    "    trend=\"up\" if not math.isnan(m[\"SMA5\"]) and not math.isnan(m[\"SMA20\"]) and m[\"SMA5\"]>=m[\"SMA20\"] else \"down/flat\"\n",
    "    fred_bits=[]\n",
    "    if fred:\n",
    "        for k in [\"10Y Treasury Yield (%)\",\"Fed Funds Rate (%)\",\"Unemployment Rate (%)\"]:\n",
    "            if k in fred: v=fred[k]; fred_bits.append(f\"{k.split(' (')[0]} {v['value']} (as of {v['date']})\")\n",
    "    macro=\" | \".join(fred_bits) if fred_bits else \"macro: n/a\"\n",
    "    return (f\"{symbol}: r5={_fmt(m['R5%'])}% r10={_fmt(m['R10%'])}% r20={_fmt(m['R20%'])}% \"\n",
    "            f\"SMA5={_fmt(m['SMA5'])} vs SMA20={_fmt(m['SMA20'])} → trend {trend}. \"\n",
    "            f\"Vol10={_fmt(m['Vol10%'])}%. {macro}\")\n",
    "\n",
    "SPECIALISTS={\"earnings\": analyze_earnings, \"analyst\": analyze_news, \"macro\": analyze_news,\n",
    "             \"ma\": analyze_news, \"legal\": analyze_news, \"product\": analyze_news,\n",
    "             \"capital\": analyze_news, \"management\": analyze_news, \"supply\": analyze_news,\n",
    "             \"risk\": analyze_news, \"news\": analyze_news, \"market\": analyze_market}\n",
    "\n",
    "def route_docs(docs: List[Dict])->Dict[str,List[Dict]]:\n",
    "    buckets={}\n",
    "    for d in docs:\n",
    "        label=d.get(\"label\",\"news\")\n",
    "        buckets.setdefault(label,[]).append(d)\n",
    "    return buckets\n",
    "\n",
    "def run_specialists(symbol: str, buckets: Dict[str,List[Dict]], *, prices=None, fred=None)->Dict[str,str]:\n",
    "    out={}\n",
    "    for label,docs in buckets.items():\n",
    "        if SPECIALISTS.get(label) is analyze_market:\n",
    "            out[label]=analyze_market(symbol, docs, prices=prices, fred=fred)\n",
    "        else:\n",
    "            out[label]=SPECIALISTS.get(label, analyze_news)(symbol, docs)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c5b83c-4212-44dc-9f18-29ca3289bc81",
   "metadata": {},
   "source": [
    "## Evaluator–Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "877782b3-e721-428e-a4eb-8166c586948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ValidationError, conint\n",
    "from typing import Dict, Any\n",
    "import json, re\n",
    "\n",
    "class EvalJSON(BaseModel):\n",
    "    accuracy: conint(ge=1, le=5)\n",
    "    specificity: conint(ge=1, le=5)\n",
    "    evidence: conint(ge=1, le=5)\n",
    "    risks: conint(ge=1, le=5)\n",
    "    actionability: conint(ge=1, le=5)\n",
    "    feedback: str = Field(default=\"\")\n",
    "\n",
    "WEIGHTS = {\"accuracy\":0.30,\"specificity\":0.15,\"evidence\":0.20,\"risks\":0.15,\"actionability\":0.20}\n",
    "THRESHOLD = 78.0\n",
    "MAX_OPT_PASSES = 1\n",
    "\n",
    "RUBRIC_MSG=('Score 1–5 on accuracy, specificity, evidence, risks, actionability. '\n",
    "            'Return ONLY JSON like {\"accuracy\":3,\"specificity\":3,\"evidence\":3,\"risks\":3,\"actionability\":3,\"feedback\":\"...\"}')\n",
    "\n",
    "def _json_from_text(txt:str)->Dict[str,Any]:\n",
    "    try: return json.loads(txt)\n",
    "    except: pass\n",
    "    m=re.search(r\"\\{.*\\}\",txt,re.S)\n",
    "    if m:\n",
    "        try: return json.loads(m.group(0))\n",
    "        except: pass\n",
    "    out={}\n",
    "    for k in [\"accuracy\",\"specificity\",\"evidence\",\"risks\",\"actionability\"]:\n",
    "        mm=re.search(fr'\"?{k}\"?\\s*:\\s*(\\d)',txt,re.I)\n",
    "        if mm: out[k]=int(mm.group(1))\n",
    "    fb=re.search(r'\"?feedback\"?\\s*:\\s*\"(.*)\"',txt,re.S|re.I)\n",
    "    out[\"feedback\"]=(fb.group(1) if fb else txt)[:1200]\n",
    "    return out\n",
    "\n",
    "def _validate_eval(d:Dict[str,Any])->EvalJSON:\n",
    "    for k in [\"accuracy\",\"specificity\",\"evidence\",\"risks\",\"actionability\"]:\n",
    "        try: d[k]=max(1,min(5,int(d.get(k,3))))\n",
    "        except: d[k]=3\n",
    "    d.setdefault(\"feedback\",\"\")\n",
    "    try: return EvalJSON(**d)\n",
    "    except ValidationError: return EvalJSON(**{**{k:3 for k in [\"accuracy\",\"specificity\",\"evidence\",\"risks\",\"actionability\"]}, \"feedback\": d.get(\"feedback\",\"\")})\n",
    "\n",
    "def evaluate_strict(llm, symbol:str, draft:str)->Dict[str,Any]:\n",
    "    msgs=[{\"role\":\"system\",\"content\":\"You are a strict finance editor. Output JSON only.\"},\n",
    "          {\"role\":\"user\",\"content\": f\"{RUBRIC_MSG}\\n\\nDRAFT for {symbol}:\\n{draft}\"}]\n",
    "    raw=llm.chat(msgs, max_tokens=350)\n",
    "    ej=_validate_eval(_json_from_text(raw))\n",
    "    overall=sum(getattr(ej,k)*w for k,w in WEIGHTS.items())/5*100.0\n",
    "    return {\"raw\":raw,\"json\":ej.model_dump(),\"overall\":round(overall,1)}\n",
    "\n",
    "def optimize_once(llm, symbol:str, draft:str, feedback:str)->str:\n",
    "    msgs=[{\"role\":\"system\",\"content\":\"You turn finance-editor feedback into concise, evidence-based briefs.\"},\n",
    "          {\"role\":\"user\",\"content\": (f\"Improve the draft for {symbol}. Keep under 220 words. \"\n",
    "                                     f\"Be specific, cite concrete items already present; avoid speculation.\\n\"\n",
    "                                     f\"FEEDBACK:\\n{feedback}\\n\\nDRAFT:\\n{draft}\")}]\n",
    "    txt=llm.chat(msgs, max_tokens=500)\n",
    "    ws=txt.split(); return \" \".join(ws[:220])\n",
    "\n",
    "def eval_optimize_loop(llm, symbol:str, draft:str, *, threshold:float=THRESHOLD, max_iters:int=MAX_OPT_PASSES):\n",
    "    history=[]; current=\" \".join(draft.split()[:220])\n",
    "    for i in range(max_iters):\n",
    "        ev=evaluate_strict(llm, symbol, current); history.append(ev)\n",
    "        if ev[\"overall\"]>=threshold: return {\"final\":current,\"evals\":history}\n",
    "        fb=ev[\"json\"][\"feedback\"] or \"Tighten, add evidence, clarify risks/catalysts.\"\n",
    "        current=optimize_once(llm, symbol, current, fb)\n",
    "    ev=evaluate_strict(llm, symbol, current); history.append(ev)\n",
    "    return {\"final\":current,\"evals\":history}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fff669-6604-4e9f-a1db-50d05a134101",
   "metadata": {},
   "source": [
    "## Agent + wiring + run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47a64394-2244-4512-bb38-b3647f07acd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== PLAN ==\n",
      "- Fetch prices\n",
      "- Fetch news\n",
      "- Prompt chain\n",
      "- Route to specialists\n",
      "- Draft brief\n",
      "[openai] retry 1/6 status=429 sleep=0.93s\n",
      "[openai] retry 2/6 status=429 sleep=1.23s\n",
      "[openai] retry 3/6 status=429 sleep=3.72s\n",
      "[openai] retry 4/6 status=429 sleep=7.76s\n",
      "[openai] retry 5/6 status=429 sleep=14.13s\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "429 Client Error: Too Many Requests for url: https://api.openai.com/v1/chat/completions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# change as needed\u001b[39;00m\n\u001b[1;32m     62\u001b[0m plan\u001b[38;5;241m=\u001b[39mresearcher\u001b[38;5;241m.\u001b[39mplan(symbol); \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== PLAN ==\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m- \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m- \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(plan))\n\u001b[0;32m---> 63\u001b[0m res\u001b[38;5;241m=\u001b[39mresearcher\u001b[38;5;241m.\u001b[39mact(symbol, days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     64\u001b[0m result\u001b[38;5;241m=\u001b[39meval_optimize_loop(llm, symbol, res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdraft\u001b[39m\u001b[38;5;124m\"\u001b[39m], threshold\u001b[38;5;241m=\u001b[39mTHRESHOLD, max_iters\u001b[38;5;241m=\u001b[39mMAX_OPT_PASSES)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m== FINAL BRIEF ==\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mresult[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[26], line 32\u001b[0m, in \u001b[0;36mResearchAgent.act\u001b[0;34m(self, symbol, days)\u001b[0m\n\u001b[1;32m     30\u001b[0m tagged\u001b[38;5;241m=\u001b[39mpc_classify(items)\n\u001b[1;32m     31\u001b[0m extracted\u001b[38;5;241m=\u001b[39mpc_extract(tagged)\n\u001b[0;32m---> 32\u001b[0m summary\u001b[38;5;241m=\u001b[39mpc_summarize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m], symbol, extracted)\n\u001b[1;32m     34\u001b[0m buckets\u001b[38;5;241m=\u001b[39mroute_docs(tagged)\n\u001b[1;32m     35\u001b[0m specialist\u001b[38;5;241m=\u001b[39mrun_specialists(symbol, buckets, prices\u001b[38;5;241m=\u001b[39mprices, fred\u001b[38;5;241m=\u001b[39mfred)\n",
      "Cell \u001b[0;32mIn[20], line 73\u001b[0m, in \u001b[0;36mpc_summarize\u001b[0;34m(llm, symbol, items)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m kp \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m\"\u001b[39m,[])[:\u001b[38;5;241m2\u001b[39m]: bullets\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  • \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m prompt\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a finance analyst. Summarize these items for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in 120-180 words, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling out catalysts and risks.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(bullets))\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mchat([{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBe concise, neutral, decision-useful.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     74\u001b[0m                  {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:prompt}], max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 42\u001b[0m, in \u001b[0;36mLLM.chat\u001b[0;34m(self, messages, max_tokens)\u001b[0m\n\u001b[1;32m     39\u001b[0m         r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(r\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m\"\u001b[39m], json\u001b[38;5;241m=\u001b[39mpayload, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     40\u001b[0m     r\u001b[38;5;241m.\u001b[39mraise_for_status(); \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[0;32m---> 42\u001b[0m r \u001b[38;5;241m=\u001b[39m guarded_call(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m, OPENAI_BUCKET, OPENAI_Q, OPENAI_CB, _post, max_retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, base\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, max_sleep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20.0\u001b[39m)\n\u001b[1;32m     43\u001b[0m text \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     44\u001b[0m cache_set(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m, ckey, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text})\n",
      "Cell \u001b[0;32mIn[7], line 89\u001b[0m, in \u001b[0;36mguarded_call\u001b[0;34m(name, bucket, queue, breaker, fn, max_retries, base, max_sleep)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries):\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m         resp \u001b[38;5;241m=\u001b[39m fn(); breaker\u001b[38;5;241m.\u001b[39mrecord_success(); \u001b[38;5;28;01mreturn\u001b[39;00m resp\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     91\u001b[0m         status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[10], line 40\u001b[0m, in \u001b[0;36mLLM.chat.<locals>._post\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mis_redirect \u001b[38;5;129;01mand\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m307\u001b[39m,\u001b[38;5;241m308\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     39\u001b[0m     r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(r\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m\"\u001b[39m], json\u001b[38;5;241m=\u001b[39mpayload, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 40\u001b[0m r\u001b[38;5;241m.\u001b[39mraise_for_status(); \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://api.openai.com/v1/chat/completions"
     ]
    }
   ],
   "source": [
    "# memory\n",
    "import json\n",
    "class Memory:\n",
    "    def __init__(self, path:str=\"data/memory.json\"):\n",
    "        self.path=path; pathlib.Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        if not pathlib.Path(path).exists(): pathlib.Path(path).write_text(\"[]\",\"utf-8\")\n",
    "    def remember(self, shard:dict):\n",
    "        arr=json.loads(open(self.path,\"r\",encoding=\"utf-8\").read()); arr.append(shard)\n",
    "        open(self.path,\"w\",encoding=\"utf-8\").write(json.dumps(arr,indent=2))\n",
    "    def recall(self, symbol:str, limit:int=2):\n",
    "        try:\n",
    "            arr=json.loads(open(self.path,\"r\",encoding=\"utf-8\").read())\n",
    "            return [a for a in arr[::-1] if a.get(\"symbol\")==symbol][:limit]\n",
    "        except: return []\n",
    "\n",
    "# agent\n",
    "from typing import Any\n",
    "class ResearchAgent:\n",
    "    name=\"researcher\"\n",
    "    def __init__(self, tools:dict[str,Any], memory:Memory):\n",
    "        self.tools=tools; self.memory=memory\n",
    "    def plan(self, symbol:str)->list[str]:\n",
    "        return [\"Fetch prices\",\"Fetch news\",\"Prompt chain\",\"Route to specialists\",\"Draft brief\"]\n",
    "    def act(self, symbol:str, days:int=20)->dict:\n",
    "        prices=self.tools[\"prices\"].fetch(symbol, days=days)\n",
    "        news=self.tools[\"news\"].fetch(symbol, limit=12)\n",
    "        fred=self.tools[\"fred\"].latest_snapshot() if self.tools.get(\"fred\") else {}\n",
    "\n",
    "        items=pc_preprocess(pc_ingest(news))\n",
    "        tagged=pc_classify(items)\n",
    "        extracted=pc_extract(tagged)\n",
    "        summary=pc_summarize(self.tools[\"llm\"], symbol, extracted)\n",
    "\n",
    "        buckets=route_docs(tagged)\n",
    "        specialist=run_specialists(symbol, buckets, prices=prices, fred=fred)\n",
    "\n",
    "        m=build_metrics(prices); mtable=metrics_table(m)\n",
    "        market_line=analyze_market(symbol, [], prices=prices, fred=fred)\n",
    "\n",
    "        draft=(\"\\n\".join([\n",
    "            f\"Prices (last {len(prices.get('history',[]))} days) fetched.\",\n",
    "            specialist.get(\"earnings\",\"\"), specialist.get(\"analyst\",\"\"), specialist.get(\"macro\",\"\"),\n",
    "            specialist.get(\"ma\",\"\"), specialist.get(\"legal\",\"\"), specialist.get(\"product\",\"\"), specialist.get(\"news\",\"\"),\n",
    "            market_line, \"Metrics:\", mtable, \"News Summary:\\n\"+summary\n",
    "        ])).strip()\n",
    "\n",
    "        self.memory.remember({\"symbol\":symbol,\"notes\":{**specialist,\"macro\":fred},\"last_summary\":summary[:500]})\n",
    "        return {\"prices\":prices,\"news\":news,\"draft\":draft,\"macro\":fred,\"metrics\":m}\n",
    "\n",
    "# wire\n",
    "llm = LLM(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "prices = PriceTool()\n",
    "news = NewsTool()\n",
    "fred = FREDTool()\n",
    "memory = Memory(str(mem_path))\n",
    "\n",
    "TOOLS={\"llm\":llm,\"prices\":prices,\"news\":news,\"fred\":fred}\n",
    "researcher=ResearchAgent(TOOLS, memory)\n",
    "\n",
    "# run\n",
    "symbol=\"AAPL\"  # change as needed\n",
    "plan=researcher.plan(symbol); print(\"== PLAN ==\\n- \"+\"\\n- \".join(plan))\n",
    "res=researcher.act(symbol, days=20)\n",
    "result=eval_optimize_loop(llm, symbol, res[\"draft\"], threshold=THRESHOLD, max_iters=MAX_OPT_PASSES)\n",
    "\n",
    "print(\"\\n== FINAL BRIEF ==\\n\"+result[\"final\"])\n",
    "print(\"\\n== MEMORY (latest) ==\\n\", memory.recall(symbol, limit=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02555552-557d-4b5b-82af-95b8b76c2cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
